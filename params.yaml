# ============================================
# PROJECT CONFIGURATION
# ============================================
project:
  name: "emotion_detection"
  version: "1.0.0"
  description: "Real-time facial emotion detection with custom dataset"
  author: "Your Name"

# ============================================
# DATA CONFIGURATION
# ============================================
data:
  data_version: 1
  total_images: 351
  num_people: 4
  num_classes: 5
  
  image_size: [224, 224]
  color_mode: "rgb"
  channels: 3
  
  train_size: 0.8
  val_size: 0.1
  test_size: 0.1
  random_state: 42
  
  class_distribution:
    angry: 51
    happy: 102
    neutral: 80
    sad: 76
    surprise: 42
  
  classes:
    0: "angry"
    1: "happy"
    2: "sad"
    3: "neutral"
    4: "surprise"

# ============================================
# REAL-TIME AUGMENTATION
# ============================================
preprocessing:
  image_size: [224, 224]
  use_realtime_augmentation: true
  augmentation:
    enabled: true
    rotation_range: 15
    horizontal_flip: true
    width_shift_range: 0.1
    height_shift_range: 0.1
    brightness_range: [0.85, 1.15]
    zoom_range: 0.1
    fill_mode: "nearest"

# ============================================
# MODEL CONFIGURATION
# ============================================
model:
  architecture: "EfficientNetB0"
  pretrained: true
  freeze_base: true
  dense_units: 128
  dropout_rate: 0.5
  num_classes: 5
  activation: "softmax"

# ============================================
# TRAINING CONFIGURATION
# ============================================
training:
  batch_size: 32
  epochs: 50
  initial_learning_rate: 0.001
  optimizer: "adam"
  loss: "categorical_crossentropy"
  metrics:
    - accuracy
    - precision
    - recall
    - f1_score
  early_stopping:
    enabled: true
    patience: 10
    monitor: "val_accuracy"
  checkpointing:
    enabled: true
    monitor: "val_accuracy"
    save_best_only: true

# ============================================
# MLFLOW EXPERIMENT TRACKING
# ============================================
tracking:
  experiment_name: "emotion_detection"
  run_name: "efficientnet_realtime_aug_v1"
  tags:
    dataset: "custom_collected"
    num_images: "351"
    num_people: "4"
    model: "EfficientNetB0"

# ============================================
# API CONFIGURATION
# ============================================
api:
  host: "0.0.0.0"
  port: 5000
  debug: false
  endpoints:
    predict: "/predict"
    predict_batch: "/predict_batch"
    health: "/health"
    model_info: "/model_info"
  max_file_size: 5
  allowed_extensions: ["jpg", "jpeg", "png"]

# ============================================
# PATHS
# ============================================
paths:
  raw_data: "data/raw"
  processed_data: "data/processed"
  saved_models: "models/saved_models"
  checkpoints: "models/checkpoints"
  logs: "logs"
  examples: "examples"

# ============================================
# DVC CONFIGURATION
# ============================================
dvc:
  remote_name: "gcs_storage"
  bucket_name: "emotion-detection-mlops-data"

# ============================================
# REPRODUCIBILITY
# ============================================
seed: 42